# ==========================================
# FINAL REPORT IMPLEMENTATION
# Includes Hyperparameter Tuning, Robust Preprocessing, and NN Models
# ==========================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random

# Sklearn Imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import (
    accuracy_score, f1_score, mean_absolute_error, 
    mean_squared_error, confusion_matrix, ConfusionMatrixDisplay
)
from sklearn.compose import ColumnTransformer

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.inspection import permutation_importance

# Set seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

print("TensorFlow Version:", tf.__version__)

# ==========================================
# PART 1: Data Loading & Preprocessing
# ==========================================

print("\n--- 1. Loading and Preprocessing Data ---")

df = pd.read_csv("train.csv")
print(f"Dataset loaded. Dimensions: {df.shape}")

# 2. Feature Engineering
df['datetime'] = pd.to_datetime(df['datetime'])
cols_to_drop = [c for c in ['casual', 'registered'] if c in df.columns]
df = df.drop(columns=cols_to_drop) 

df['hour'] = df['datetime'].dt.hour
df['weekday'] = df['datetime'].dt.weekday
df['month'] = df['datetime'].dt.month
df['year'] = df['datetime'].dt.year
df['feels_like_gap'] = df['atemp'] - df['temp']
df['rush_hour'] = df['hour'].isin([7,8,9,16,17,18]).astype(int)

# Classification Target
df['is_peak_hour'] = (df['count'] >= 100).astype(int)

# Check Class Balance
print("Class Balance (is_peak_hour):")
print(df['is_peak_hour'].value_counts(normalize=True))

# 3. Advanced Preprocessing Strategy
categorical_features = ['hour', 'season', 'weather', 'weekday']
numeric_features = ['temp', 'atemp', 'humidity', 'windspeed', 'feels_like_gap', 'month', 'year']

X = df[numeric_features + categorical_features] 
y_class = df['is_peak_hour']
y_reg = df['count']

# 4. Train/Val/Test Split
X_train_raw, X_temp, y_class_train, y_class_temp, y_reg_train, y_reg_temp = train_test_split(
    X, y_class, y_reg, test_size=0.30, random_state=42, stratify=y_class
)
X_val_raw, X_test_raw, y_class_val, y_class_test, y_reg_val, y_reg_test = train_test_split(
    X_temp, y_class_temp, y_reg_temp, test_size=0.50, random_state=42, stratify=y_class_temp
)

# 5. Pipeline Transformer
# Scale numerics, One-Hot Encode categoricals
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ]
)

# Fit on Train, Transform all
X_train_scaled = preprocessor.fit_transform(X_train_raw).astype('float32')
X_val_scaled = preprocessor.transform(X_val_raw).astype('float32')
X_test_scaled = preprocessor.transform(X_test_raw).astype('float32')

print(f"Preprocessing Complete. Feature Matrix Shape: {X_train_scaled.shape}")

# ==========================================
# PART 2: Hyperparameter Tuning (Requirement #2)
# ==========================================

print("\n--- 2. Hyperparameter Tuning Summary (Random Search) ---")

def create_model(input_dim, units=64, dropout_rate=0.2, learning_rate=0.001, output_act='sigmoid', loss='binary_crossentropy'):
    model = Sequential([
        Dense(units, activation='relu', input_shape=(input_dim,)),
        BatchNormalization(),
        Dropout(dropout_rate),
        Dense(units // 2, activation='relu'),
        BatchNormalization(),
        Dropout(dropout_rate / 2),
        Dense(1, activation=output_act)
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy' if output_act=='sigmoid' else 'mae'])
    return model

# Random Search Configuration
param_grid = {
    'units': [64, 128],            
    'dropout_rate': [0.1, 0.2, 0.3], 
    'learning_rate': [0.001, 0.0005] 
}

best_score = 0
best_params = {}
input_dim = X_train_scaled.shape[1]

print("Tuning Classification Model (10 iterations)...")
for i in range(10): 
    # Randomly sample params
    p = {k: random.choice(v) for k, v in param_grid.items()}
    
    # Train quick model to find best params
    model = create_model(input_dim, units=p['units'], dropout_rate=p['dropout_rate'], learning_rate=p['learning_rate'])
    history = model.fit(X_train_scaled, y_class_train, epochs=20, batch_size=64, verbose=0, validation_data=(X_val_scaled, y_class_val))
    
    val_acc = max(history.history['val_accuracy'])
    print(f"Iter {i+1}: {p} -> Val Acc: {val_acc:.4f}")
    
    if val_acc > best_score:
        best_score = val_acc
        best_params = p

print(f"Best Params found: {best_params}")

# ==========================================
# PART 3: Final Model Training (Requirement #1)
# ==========================================

print("\n--- 3. Training Final Models ---")

# Callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0)

# 3.1 Final Classification NN
# If best params failed (acc < 0.6) for some reason, fallback to known good params
if best_score < 0.6:
    print("Warning: Random Search found poor params. Using manual fallback.")
    best_params = {'units': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}

model_class = create_model(input_dim, units=best_params['units'], dropout_rate=best_params['dropout_rate'], learning_rate=best_params['learning_rate'])
history_class = model_class.fit(
    X_train_scaled, y_class_train,
    validation_data=(X_val_scaled, y_class_val),
    epochs=100, batch_size=64,
    callbacks=[early_stop, reduce_lr],
    verbose=0
)

# 3.2 Final Regression NN (Linear Output)
model_reg = create_model(input_dim, units=best_params['units'], dropout_rate=best_params['dropout_rate'], learning_rate=best_params['learning_rate'], output_act='linear', loss='mse')
history_reg = model_reg.fit(
    X_train_scaled, y_reg_train,
    validation_data=(X_val_scaled, y_reg_val),
    epochs=100, batch_size=64,
    callbacks=[early_stop, reduce_lr],
    verbose=0
)

# ==========================================
# PART 4: Required Plots (Requirement #7)
# ==========================================

# Plot 1: Classification Learning Curve
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history_class.history['accuracy'], label='Train')
plt.plot(history_class.history['val_accuracy'], label='Val')
plt.title("Plot 1: Classification Accuracy vs Epochs")
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history_class.history['loss'], label='Train')
plt.plot(history_class.history['val_loss'], label='Val')
plt.title("Classification Loss")
plt.legend()
plt.show()

# Plot 2: Regression Learning Curve
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history_reg.history['mae'], label='Train')
plt.plot(history_reg.history['val_mae'], label='Val')
plt.title("Plot 2: Regression MAE vs Epochs")
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history_reg.history['loss'], label='Train')
plt.plot(history_reg.history['val_loss'], label='Val')
plt.title("Regression Loss (MSE)")
plt.legend()
plt.show()

# Plot 3: Confusion Matrix
y_pred_prob = model_class.predict(X_test_scaled, verbose=0)
y_pred_class = (y_pred_prob >= 0.5).astype(int).flatten()
cm = confusion_matrix(y_class_test, y_pred_class)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Off-peak', 'Peak'])
disp.plot(cmap='Blues')
plt.title("Plot 3: Confusion Matrix (Final NN)")
plt.show()

# Plot 4: Residuals
y_pred_reg = model_reg.predict(X_test_scaled, verbose=0).flatten()
residuals = y_reg_test - y_pred_reg
plt.figure(figsize=(8, 5))
plt.scatter(y_pred_reg, residuals, alpha=0.3, color='purple')
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted Count")
plt.ylabel("Residuals")
plt.title("Plot 4: Residuals vs Predicted (Final NN)")
plt.show()

# Plot 5: Feature Importance (Permutation)
print("Calculating Feature Importance...")
class KerasWrapper:
    def __init__(self, model): 
        self.model = model
    def fit(self, X, y): 
        return self
    def predict(self, X): 
        return (self.model.predict(X, verbose=0) >= 0.5).astype(int).flatten()
    def score(self, X, y):
        # REQUIRED: Scikit-learn needs a score method to calculate importance
        return accuracy_score(y, self.predict(X))

wrapper = KerasWrapper(model_class)
perm_results = permutation_importance(wrapper, X_val_scaled, y_class_val, n_repeats=5, random_state=42)

# Get feature names from preprocessor
ohe_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
all_feats = numeric_features + list(ohe_cols)

imp_df = pd.DataFrame({'feature': all_feats, 'importance': perm_results.importances_mean})
top_10 = imp_df.sort_values(by='importance', ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=top_10, orient='h', color='teal')
plt.title("Plot 5: Feature Importance (Neural Network)")
plt.show()

# ==========================================
# PART 5: Required Tables (Requirement #8)
# ==========================================

# Final Metrics
nn_acc = accuracy_score(y_class_test, y_pred_class)
nn_f1 = f1_score(y_class_test, y_pred_class)
nn_mae = mean_absolute_error(y_reg_test, y_pred_reg)
nn_rmse = np.sqrt(mean_squared_error(y_reg_test, y_pred_reg))

# Baseline Placeholders (Replace with your actual Midpoint values!)
dt_acc = 0.8959 
dt_f1 = 0.9154
dt_mae = 51.52
dt_rmse = 84.63

print("\n--- Table 1: Classification Comparison ---")
tbl1 = pd.DataFrame({
    'Metric': ['Accuracy', 'F1 Score'],
    'Classical (Decision Tree)': [dt_acc, dt_f1],
    'Neural Network (Final)': [nn_acc, nn_f1]
})
print(tbl1)

print("\n--- Table 2: Regression Comparison ---")
tbl2 = pd.DataFrame({
    'Metric': ['MAE', 'RMSE'],
    'Classical (Decision Tree)': [dt_mae, dt_rmse],
    'Neural Network (Final)': [nn_mae, nn_rmse]
})
print(tbl2)
